{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86defd21-7df3-4a7c-996b-75dac5972db0",
   "metadata": {},
   "source": [
    "# Surgeo Code Walkthrough with Additional Steps\n",
    "<b> Emilio Ramos Monzalvo - 09/01/2021 </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e8c785-4f8e-4172-83b2-7f634194e2fd",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c796bc51-9978-4593-bfd7-c3e68cd386ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import string\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8526b9b3-452f-4109-9b52-a46d46ffe3b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'geopandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32824/2671770506.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgeopandas\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextra\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrate_limiter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRateLimiter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mgeopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgeocoders\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNominatim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'geopandas'"
     ]
    }
   ],
   "source": [
    "import geopandas\n",
    "\n",
    "from geopy.extra.rate_limiter import RateLimiter\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import folium\n",
    "from folium.plugins import FastMarkerCluster\n",
    "from folium.utilities import if_pandas_df_convert_to_numpy, validate_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fe3b81-7c29-4165-b2d7-377e82024720",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "import sparse_dot_topn.sparse_dot_topn as ct  # cosine matching\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "import fuzzywuzzy.process as fuzz_process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ceab96-05e0-4257-b7d7-7c6c7e12c4a1",
   "metadata": {},
   "source": [
    "## Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98279ca5-9eeb-4f62-b3fa-a6b1134b40ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "RACE_COLS = ['white', 'black', 'api', 'native', 'multiple', 'hispanic']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d9780-5ba9-468f-8447-20b6e26ecfe6",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215feb80-2810-4328-91ac-b7e8815fba20",
   "metadata": {},
   "source": [
    "### Probability of First Name Given Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72213c75-749d-4a81-83f5-df6d1e15b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_g_r = pd.read_csv(\n",
    "            'Data/prob_first_name_given_race_harvard.csv',\n",
    "            index_col='name',\n",
    "            na_values=[''],\n",
    "            keep_default_na=False,\n",
    "        )\n",
    "print('Number of Rows: ', len(fn_g_r))\n",
    "fn_g_r.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec6a091-a23f-4f8c-bc4c-adf7fd03c642",
   "metadata": {},
   "source": [
    "### Probability of Race Given Surname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6d0496-dbfb-4a17-be6a-256d3d756159",
   "metadata": {},
   "outputs": [],
   "source": [
    "r_g_sn = pd.read_csv(\n",
    "            'Data/prob_race_given_surname_2010.csv',\n",
    "            index_col='name',\n",
    "            na_values=[''],\n",
    "            keep_default_na=False,\n",
    "        )\n",
    "print('Number of Rows: ', len(r_g_sn))\n",
    "r_g_sn.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfcd0a-5d6e-4818-b886-78c286dc3f1a",
   "metadata": {},
   "source": [
    "### Probability of ZCTA Given Race"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f181420-6828-462c-96e2-537b8b855ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "zcta_g_race = pd.read_csv(\n",
    "            'Data/prob_zcta_given_race_2010.csv',\n",
    "            index_col='zcta5',\n",
    "            na_values=[''],\n",
    "            keep_default_na=False,\n",
    "        )\n",
    "print('Number of Rows: ', len(zcta_g_race))\n",
    "zcta_g_race.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f739e076-b2cf-4e07-937a-ce84e75d39aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "## PreProcessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26844179-465e-4dd0-872d-23d7344eddd5",
   "metadata": {},
   "source": [
    "### Names (First and Last Names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83feb02-2328-405d-b7a4-0f566cef3696",
   "metadata": {},
   "source": [
    "<b> Here we would need to add a way to approximate how similar a name is to another if it does not exist on the table. </b>\n",
    "* Use Fuzzy matching to get the closest name to an already existing name.\n",
    "    - Inneficient computation time (How many will we be processing? I.e., is computation time important?)\n",
    "    - Does not take into consideration the roots of the names. It only finds the closest related name instead.\n",
    "* Use bigrams or other methods to include roots of the names for better matching.\n",
    "    - Cosine Mathcing using Bigrams:\n",
    "    - https://towardsdatascience.com/surprisingly-effective-way-to-name-matching-in-python-1a67328e670e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c979e686-fa6a-4ae5-9f41-fda7c88bd287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_names(names: pd.Series) -> pd.Series:\n",
    "        \"\"\"Take names and run a normalization routine\"\"\"\n",
    "        \n",
    "        # Make a transalation table of unwanted characers\n",
    "        unwanted_characters = (\n",
    "            string.digits +\n",
    "            string.punctuation +\n",
    "            string.whitespace\n",
    "        )\n",
    "        \n",
    "        # Remove unwanted characters efficiently\n",
    "        translation_table =  str.maketrans('', '', unwanted_characters)\n",
    "        \n",
    "        # Run our string operations (remember NAN is a valid name)\n",
    "        output = (\n",
    "            names.fillna('')\n",
    "                 .astype(str)\n",
    "                 .str.translate(translation_table)\n",
    "                 .str.upper()\n",
    "                 .str.replace(r'\\s?J\\.*?R\\.*\\s*?$', '', regex=True)\n",
    "                 .str.replace(r'\\s?S\\.*?R\\.*\\s*?$', '', regex=True)\n",
    "                 .str.replace(r'\\s?III\\s*?$',      '', regex=True)\n",
    "                 .str.replace(r'\\s?IV\\s*?$',       '', regex=True)\n",
    "        )\n",
    "        output.name = 'name'\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627053c2-1490-4e7d-8eab-2f4f8a04a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process / Normalize Names\n",
    "fn_g_r_norm = fn_g_r.copy()\n",
    "fn_g_r_norm.index = preprocess_names(fn_g_r_norm.index.to_series())\n",
    "\n",
    "r_g_sn_norm = r_g_sn.copy()\n",
    "r_g_sn_norm.index = preprocess_names(r_g_sn_norm.index.to_series())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eec5e0a-3528-436e-95c2-7c087f1b4488",
   "metadata": {
    "tags": []
   },
   "source": [
    "### ZCTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fd7e18-c8e8-47f0-9b9c-7eed88d5c2d3",
   "metadata": {},
   "source": [
    "<b> What if the address provided does not have a Zip Code? Or What if it does not appear in the data used to create the population summary?</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d355eb-47f2-4ed3-be2a-a1e7f2a9e0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_zctas(zcta: pd.Series) -> pd.Series:\n",
    "        \"\"\"Transform ZCTAs into standardized strings\"\"\"\n",
    "        converted = pd.Series(zcta.values, dtype=str).str.strip()\n",
    "        zfilled = converted.str.zfill(5)\n",
    "        zfilled.name = 'zcta5'\n",
    "        return zfilled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f57092-d9a9-4ca8-b27a-e26d8023e694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre Process / Normalize Zip Codes\n",
    "zcta_g_race_norm = zcta_g_race.copy()\n",
    "zcta_g_race_norm.index = preprocess_zctas(zcta_g_race_norm.index.to_series())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09cc2690-0620-4f2d-ae72-9d50cfe4a3bb",
   "metadata": {},
   "source": [
    "## Get Probabilities Based on Names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "692bcfc0-ae3d-47ac-82bc-87d43544b823",
   "metadata": {},
   "source": [
    "### Get The Most Similiar Name Already Known"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f2e440-23ee-42b5-a14a-caa583278acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_names_tfidf(new_names: pd.Series, old_names: pd.Series, NGRAMS=2):\n",
    "    \n",
    "    # Vectorize using TfidVectorizer and Ngrams\n",
    "    vect = TfidfVectorizer(analyzer='char', max_df=0.3, min_df=3, ngram_range=(NGRAMS, NGRAMS), lowercase=False)\n",
    "    tf_idf_matrix_old = vect.fit_transform(old_names)\n",
    "    tf_idf_matrix_new = vect.transform(new_names)\n",
    "    \n",
    "    return tf_idf_matrix_new, tf_idf_matrix_old\n",
    "\n",
    "def cosine_similarity_topn(A: csr_matrix, B: csr_matrix, topn: int = 10, lower_bound: int=0) -> csr_matrix:\n",
    "        # force A and B as a CSR matrix.\n",
    "        # If they have already been CSR, there is no overhead\n",
    "        A = A.tocsr()\n",
    "        B = B.tocsr()\n",
    "        M, _ = A.shape\n",
    "        _, N = B.shape\n",
    "\n",
    "        idx_dtype = np.int32\n",
    "\n",
    "        nnz_max = M*topn\n",
    "\n",
    "        indptr = np.zeros(M+1, dtype=idx_dtype)\n",
    "        indices = np.zeros(nnz_max, dtype=idx_dtype)\n",
    "        data = np.zeros(nnz_max, dtype=A.dtype)\n",
    "\n",
    "        ct.sparse_dot_topn(\n",
    "                M, N, np.asarray(A.indptr, dtype=idx_dtype),\n",
    "                np.asarray(A.indices, dtype=idx_dtype),\n",
    "                A.data,\n",
    "                np.asarray(B.indptr, dtype=idx_dtype),\n",
    "                np.asarray(B.indices, dtype=idx_dtype),\n",
    "                B.data,\n",
    "                topn,\n",
    "                lower_bound,\n",
    "                indptr, indices, data)\n",
    "\n",
    "        return csr_matrix((data,indices,indptr),shape=(M,N))\n",
    "    \n",
    "def get_matches_df(sparse_matrix: csr_matrix, name_vector_a: pd.Series, \n",
    "                   name_vector_b: pd.Series , topn: int=-1,\n",
    "                  max_match=100) -> pd.DataFrame:\n",
    "    \"\"\"Unpack Sparse Matrix Matches into a Data Frame\"\"\"\n",
    "    \n",
    "    non_zeros = sparse_matrix.nonzero()\n",
    "    \n",
    "    sparserows = non_zeros[0]\n",
    "    sparsecols = non_zeros[1]\n",
    "    \n",
    "    if topn > 0:\n",
    "        nr_matches = topn\n",
    "    else:\n",
    "        nr_matches = sparsecols.size\n",
    "    \n",
    "    left_side = np.empty([nr_matches], dtype=object)\n",
    "    right_side = np.empty([nr_matches], dtype=object)\n",
    "    similairity = np.zeros(nr_matches)\n",
    "\n",
    "    for index in tqdm(range(0, nr_matches), desc=\"Computing Cosine Similarities...\"):\n",
    "        left_side[index] = name_vector_a[sparserows[index]]\n",
    "        right_side[index] = name_vector_b[sparsecols[index]]\n",
    "        similairity[index] = np.floor(sparse_matrix.data[index]*100)\n",
    "    \n",
    "    matches = pd.DataFrame({'name': right_side,\n",
    "                          'match': left_side,\n",
    "                           'match_score': similairity})\n",
    "    \n",
    "    matches = matches.loc[(matches['match_score'] <= max_match)]\\\n",
    "                            .sort_values(['name', 'match_score'], ascending=[True, False])\\\n",
    "                            .reset_index(drop=True) # For removing all exact matches\n",
    "    \n",
    "    return matches\n",
    "\n",
    "def get_fuzzy_matches(old_names: pd.Series, new_names: pd.Series, cosine_match: pd.DataFrame, topn: int = 1, min_score:int = 0) -> pd.DataFrame:\n",
    "    \"\"\"Returns the topn best matches for each of the names in vector b\n",
    "        \n",
    "        old_names: Existing Names\n",
    "        new_names: New Names that need Matching\n",
    "        topn: number of results for each new name\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    fuzzy_matches = pd.DataFrame(columns=['name', 'match', 'match_score'])\n",
    "    \n",
    "    res_idx = 0\n",
    "    for new_name in tqdm(new_names.values, desc=\"Computing Fuzzy Similarities...\"):\n",
    "        \n",
    "        # Use subset of cosine names\n",
    "        most_like_names = cosine_match.loc[((cosine_match['name'] == new_name) & (cosine_match['match_score'] > 50))].match.values\n",
    "        \n",
    "        # Check if a there is a subset of best names; otherwise, compare against all old names.\n",
    "        if len(most_like_names) < 15:\n",
    "            fuzz_matches = fuzz_process.extract(new_name, old_names.values, scorer=fuzz.token_sort_ratio)\n",
    "        else:\n",
    "            fuzz_matches = fuzz_process.extract(new_name, most_like_names, scorer=fuzz.token_sort_ratio)\n",
    "            \n",
    "        if len(fuzz_matches) > 0:\n",
    "            for match in fuzz_matches:\n",
    "                fuzzy_matches.loc[res_idx] = {'name':new_name, 'match':match[0], 'match_score':match[1]}\n",
    "                res_idx += 1\n",
    "        else:\n",
    "            fuzzy_matches.loc[res_idx] = {'name':new_name, 'match':'', 'match_score':0}\n",
    "            \n",
    "    return fuzzy_matches.loc[fuzzy_matches['match_score'] > min_score].sort_values(['name', 'match_score'], ascending=[True, False]).groupby(['name']).head(topn)\n",
    "\n",
    "\n",
    "def get_most_similar_name(new_names: pd.Series, old_names: pd.Series) -> pd.DataFrame:\n",
    "    \n",
    "    # Pre-Process Names for Cosine Similarity\n",
    "    tf_idf_matrix_new, tf_idf_matrix_old = preprocess_names_tfidf(new_names=new_names, old_names=old_names)\n",
    "    \n",
    "    #  Run the optimized cosine similarity function. \n",
    "    cosine_matches = cosine_similarity_topn(A=tf_idf_matrix_old, \n",
    "                                    B=tf_idf_matrix_new.transpose(), \n",
    "                                    topn=50, lower_bound=0)\n",
    "    \n",
    "    # Get Best Matches\n",
    "    # store the  matches into new dataframe called matched_df and printing 10 samples\n",
    "    cosine_matches = get_matches_df(sparse_matrix=cosine_matches,\n",
    "                                name_vector_a=old_names, \n",
    "                                name_vector_b=new_names,\n",
    "                                topn=-1)\n",
    "    \n",
    "    # Get Fuzzy Matches as Well\n",
    "    fuzzy_match = get_fuzzy_matches(old_names=pd.Series(old_names), new_names=pd.Series(new_names), \n",
    "                                    cosine_match=cosine_matches, topn=1, min_score=0)\n",
    "    \n",
    "    \n",
    "    # Merge them both into one\n",
    "    matches_df = cosine_matches.groupby(['name']).head(1)\\\n",
    "                .merge(fuzzy_match.groupby(['name']).head(1), on=['name'], suffixes=('_cosine', '_fuzzy'), how='inner')\n",
    "    matches_df = matches_df.set_index('name')\n",
    "    \n",
    "    # Get the best match (Either from fuzzy or cosine)\n",
    "    matches_df['closest_name'] = [cos_name if cos_val > fuzz_val else fuzz_name for cos_name, cos_val, fuzz_name, fuzz_val in matches_df.values]\n",
    "    \n",
    "    return matches_df\n",
    "\n",
    "## Test\n",
    "get_most_similar_name(new_names=pd.Series(['EMILIO', 'ASHLEIGH', 'JAVIER', 'MARUGEL', 'HECTOR']), old_names=pd.Series(fn_g_r_norm.index.tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485cc378-9823-473b-95ee-b6dd545c09f8",
   "metadata": {},
   "source": [
    "### Get Probability for Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9254d8-9395-4eb2-8ef2-fb014448883b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fn_probs(fn: pd.Series, fn_probs:pd.DataFrame=fn_g_r_norm) -> pd.DataFrame:\n",
    "    \"\"\"Return the probability of first name given race for each first name given.\"\"\"\n",
    "    \n",
    "    \n",
    "    # Clean Names\n",
    "    fn_norm = preprocess_names(names=fn)\n",
    "    \n",
    "    # Get Closest Name\n",
    "    fn_matches = get_most_similar_name(new_names=fn_norm, old_names=fn_g_r_norm.index.tolist())\n",
    "    \n",
    "    # Find Entries\n",
    "    first_name_probs = fn_matches[['closest_name']].merge(\n",
    "            fn_g_r_norm,\n",
    "            left_on='closest_name',\n",
    "            right_index=True,\n",
    "            how='left',\n",
    "    )        \n",
    "    \n",
    "    return first_name_probs.loc[fn_norm]\n",
    "\n",
    "## Test\n",
    "get_fn_probs(fn=pd.Series(['Emilio', 'Ashleigh', 'Hector', 'Kiara', 'Nicole', 'Larry']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9425fe5a-aef1-40c4-84b9-057c66cb120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_surn_probs(sn: pd.Series, sn_probs:pd.DataFrame=r_g_sn_norm) -> pd.DataFrame:\n",
    "    \"\"\"Return the probability of race given surname for each sruname given.\"\"\"\n",
    "\n",
    "    # Clean Names\n",
    "    sn_norm = preprocess_names(names=sn)\n",
    "    \n",
    "    # Get Closest Name\n",
    "    sn_matches = get_most_similar_name(new_names=sn_norm, old_names=r_g_sn_norm.index.tolist())\n",
    "    \n",
    "    # Find Entries\n",
    "    surname_probs = sn_matches[['closest_name']].merge(\n",
    "            sn_probs,\n",
    "            left_on='closest_name',\n",
    "            right_index=True,\n",
    "            how='left',\n",
    "    )        \n",
    "    \n",
    "    return surname_probs.loc[sn_norm]\n",
    "\n",
    "## Test\n",
    "get_surn_probs(sn=pd.Series(['Ramos', 'Brock', 'Monzalvo', 'Berk', 'Rubenstein', 'Powell', 'Engel']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f24a99-3381-479b-857e-292fa3abf764",
   "metadata": {},
   "source": [
    "## Get Geo Race Probability Based on ZipCode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ece7fe-13a5-47bd-9653-e473fb8b0f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zipcode_from_addr(addr: pd.Series) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "    \n",
    "    return zcta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544e08c4-f3be-4cf5-8a54-2b800e847d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_probs(addr: pd.Series, ztca_probs:pd.DataFrame=zcta_g_race_norm) -> pd.DataFrame:\n",
    "    \"\"\"Return the probability of race given zcta for each address given.\"\"\"\n",
    "\n",
    "    # Clean Zipcodes\n",
    "    addr_norm = preprocess_zctas(zcta=addr)\n",
    "    \n",
    "    # Find Entries\n",
    "    geo_probs = addr_norm.to_frame().merge(\n",
    "            ztca_probs,\n",
    "            left_on='zcta5',\n",
    "            right_index=True,\n",
    "            how='left',\n",
    "    )        \n",
    "    \n",
    "    return geo_probs\n",
    "\n",
    "get_geo_probs(addr=pd.Series(['95123', '98136', '72712', '95123', '02109', '02109']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4b7d36-903b-4df4-a51e-470fd8a812a6",
   "metadata": {},
   "source": [
    "## Compute Probability using BIFSG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75920a6e-df24-47e6-9aa7-94ecc69a6830",
   "metadata": {},
   "source": [
    "![BIFSG](imgs/bayesianformula.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32919b5e-153a-4033-bbb7-47f1c6befba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_BIFSG_probs( first_name: pd.Series, \n",
    "                    surname: pd.Series,\n",
    "                    addr: pd.Series,\n",
    "                    RACE_COLS=RACE_COLS) -> pd.DataFrame:\n",
    "    \"\"\"Performs the BIFSG calculation\"\"\"\n",
    "    \n",
    "    # Get Probabilities\n",
    "    first_name_probs = get_fn_probs(fn=first_name).reset_index(drop=False)\n",
    "    sur_probs = get_surn_probs(sn=surname).reset_index(drop=False)\n",
    "    geo_probs = get_geo_probs(addr=addr).reset_index(drop=False)\n",
    "    \n",
    "    # Calculate each of the numerators\n",
    "    bifsg_numer = (\n",
    "        first_name_probs.loc[:, RACE_COLS] *\n",
    "        sur_probs.loc[:, RACE_COLS] *\n",
    "        geo_probs.loc[:, RACE_COLS]\n",
    "    )\n",
    "    \n",
    "    # Calculate the denominator\n",
    "    bifsg_denom = bifsg_numer.sum(axis=1)\n",
    "    \n",
    "    # Caluclate the bifsg probabilities (each num / denom)\n",
    "    bifsg_probs = bifsg_numer.div(bifsg_denom, axis=0)\n",
    "    \n",
    "    # Build frame from zctas, first names, surnames, and probabilities\n",
    "    bifsg_data = pd.concat([\n",
    "        first_name_probs\n",
    "            .rename(columns={'name': 'first_name', 'closest_name':'closest_first_name'})[['first_name', 'closest_first_name']],\n",
    "        sur_probs\n",
    "            .rename(columns={'name': 'surname', 'closest_name':'closest_surname'})[['surname', 'closest_surname']],\n",
    "        geo_probs['zcta5'].to_frame(),\n",
    "        bifsg_probs\n",
    "    ], axis=1)\n",
    "        \n",
    "    bifsg_data['predicted_race'] = bifsg_data[RACE_COLS].idxmax(axis=1)\n",
    "    \n",
    "    return bifsg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d8c742-6822-484f-8fee-5de1d2fa3175",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.DataFrame(zip(\n",
    "    ['Emilio', 'Hector', 'Ashleigh', 'Kiara', 'Bryn', 'Nicole', 'Larry', 'Marugel'],\n",
    "    ['Ramos', 'Monzalvo', 'Brock', 'Sanchez', 'Kirkland', 'Rubenstein', 'Berk', 'Ramos'],\n",
    "    ['95123', '72712', '98136', '72712', '78701', '02109', '02109', '72712']\n",
    "), columns = ['first_name', 'surname', 'addr'])\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b5987c-51fd-4a18-9bf8-4f107e0de782",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_BIFSG_probs(\n",
    "    first_name=test_df.first_name,\n",
    "    surname=test_df.surname,\n",
    "    addr=test_df.addr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fe8ab1-f10a-4146-b881-a646524dadf4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
